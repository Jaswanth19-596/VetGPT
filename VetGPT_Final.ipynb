{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9644b5fe",
      "metadata": {
        "id": "9644b5fe"
      },
      "source": [
        "\n",
        "## GPT from scratch in PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd998537",
      "metadata": {
        "id": "fd998537"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.nn import functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2dee99f",
      "metadata": {
        "id": "f2dee99f"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1e5aca",
      "metadata": {
        "id": "2b1e5aca",
        "outputId": "539e95d3-7cb9-473f-b40c-4f388716b6c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ef4475",
      "metadata": {
        "id": "f5ef4475"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(256)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "block_size        = 120      ## N tokens in sequence\n",
        "batch_size        = 240\n",
        "max_iters         = 6000\n",
        "eval_interval     = 500\n",
        "learning_rate     = 0.0003\n",
        "eval_iters        = 300\n",
        "vocab_size        = 88  ## 65\n",
        "\n",
        "## every id for a given token is embedded to vector of this size\n",
        "n_embd            = 512\n",
        "n_head            = 8         ## 8 attention heads\n",
        "n_layer           = 6         ## 6 eoncoder layers\n",
        "dropout           = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2849b23c",
      "metadata": {
        "id": "2849b23c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove any extra whitespace, new lines, or tabs\n",
        "    text = text.strip()\n",
        "\n",
        "    # Remove unwanted characters like non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "    # Replace multiple newlines with a single newline\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove non-informative special characters (like &, %, $, etc.)\n",
        "    text = re.sub(r'[&%$@#^*()_+=~]', '', text)\n",
        "\n",
        "    # Remove punctuation (keep it if needed for language structure)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Reduce any multiple spaces to a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "input_file2 = 'content.txt'\n",
        "\n",
        "with open(input_file2, 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "text = clean_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fbd2a2",
      "metadata": {
        "id": "a1fbd2a2",
        "outputId": "498c1d67-4cd4-4676-fb0c-18528efa375d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63\n",
            " 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "\n",
        "the_chars  = sorted(list(set(text)))\n",
        "\n",
        "vocab_size = len( the_chars )\n",
        "\n",
        "print(  len(the_chars)  )\n",
        "\n",
        "print(  ''.join(the_chars)  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd6792d",
      "metadata": {
        "id": "dbd6792d"
      },
      "outputs": [],
      "source": [
        "\n",
        "stoi = { ch:i for i, ch in enumerate(the_chars) }\n",
        "itos = { i:ch for i, ch in enumerate(the_chars) }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f94aef4e",
      "metadata": {
        "id": "f94aef4e",
        "outputId": "e813f016-8826-4ad7-b6bc-82192c8f5b27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[38, 37, 44, 44]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "encode = lambda s: [ stoi[c]          for c in s   ]\n",
        "\n",
        "encode(\"bahh\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3589a021",
      "metadata": {
        "id": "3589a021"
      },
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd044ad",
      "metadata": {
        "id": "ddd044ad"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c22efc8d",
      "metadata": {
        "id": "c22efc8d"
      },
      "source": [
        "encode = lambda s: tokenizer.encode(s)\n",
        "\n",
        "encode(\"bahh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9f391f",
      "metadata": {
        "id": "6d9f391f",
        "outputId": "749af987-0855-46b7-be11-155ff56a8336"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'bahh'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "decode = lambda l: ''.join(   itos[i] for i in l   )\n",
        "\n",
        "decode([38, 37, 44, 44])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e65b4ec0",
      "metadata": {
        "id": "e65b4ec0"
      },
      "source": [
        "decode = lambda l: tokenizer.decode(l)\n",
        "\n",
        "decode([47041, 71])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14091bc3",
      "metadata": {
        "id": "14091bc3"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = torch.tensor(   encode(text), dtype=torch.long   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15111645",
      "metadata": {
        "id": "15111645"
      },
      "outputs": [],
      "source": [
        "\n",
        "n          = int(   0.9*len(data)   )\n",
        "\n",
        "train_data = data[:n]\n",
        "val_data   = data[n:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff7ae6c",
      "metadata": {
        "id": "bff7ae6c"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_batch(split):\n",
        "    if split == \"train\":\n",
        "        data = train_data\n",
        "    else:\n",
        "        data = val_data\n",
        "\n",
        "    ix = torch.randint(   len(data) - block_size, (batch_size,)   )\n",
        "\n",
        "    x  = torch.stack(    [  data[   i : i+block_size ]     for i in ix ]    )\n",
        "    y  = torch.stack(    [  data[ i+1 : i+1+block_size ]   for i in ix ]    )\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb11fcf8",
      "metadata": {
        "id": "eb11fcf8"
      },
      "outputs": [],
      "source": [
        "\n",
        "temp_batch_size = 4\n",
        "temp_block_size = 16\n",
        "\n",
        "## select random starting points for the 4 sentences\n",
        "ix = torch.randint(\n",
        "            len(data) - block_size,\n",
        "            (temp_batch_size,)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67d3511",
      "metadata": {
        "id": "c67d3511"
      },
      "outputs": [],
      "source": [
        "\n",
        "x  = torch.stack(\n",
        "    [ data[   i : i+  temp_block_size ]   for i in ix ]\n",
        "\n",
        ")\n",
        "\n",
        "y  = torch.stack(\n",
        "    [ data[ i+1 : i+1+ temp_block_size ]  for i in ix ]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c58677ef",
      "metadata": {
        "id": "c58677ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "@torch.no_grad()    ## for efficient processing\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()   ## set to no training\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()  ## back to training\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01742ea3",
      "metadata": {
        "id": "01742ea3"
      },
      "source": [
        "\n",
        "## NN Architectures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cc1335",
      "metadata": {
        "id": "01cc1335"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
        "\n",
        "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
        "\n",
        "        self.register_buffer(\n",
        "                  'tril',\n",
        "                  tril_def\n",
        "               )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
        "\n",
        "        k = self.key(   x )            ## k = (B, T, 64)\n",
        "        q = self.query( x )            ## q = (B, T, 64)\n",
        "\n",
        "        E2 = 64     ## I think this is 64 and not 512\n",
        "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
        "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5\n",
        "\n",
        "        wei = wei.masked_fill(\n",
        "                      self.tril[:T, :T] == 0,\n",
        "                      float('-inf')\n",
        "        )\n",
        "\n",
        "        ## (B, T, T)\n",
        "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
        "        wei = self.dropout(   wei   )\n",
        "\n",
        "        ## perform weighted aggregation of values\n",
        "\n",
        "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
        "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ae3afc",
      "metadata": {
        "id": "76ae3afc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):         ## 512\n",
        "\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe67e996",
      "metadata": {
        "id": "fe67e996"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):    ## (8, 64)\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )\n",
        "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
        "        out = self.proj(  out   )\n",
        "        out = self.dropout(   out   )\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52f09aa",
      "metadata": {
        "id": "a52f09aa"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):     ## (512, 8)\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head        ## 64\n",
        "        self.sa   = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward( n_embd)    ## 512\n",
        "        self.ln1  = nn.LayerNorm(n_embd)\n",
        "        self.ln2  = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(     self.ln1(x)      )\n",
        "        x = x + self.ffwd(   self.ln2(x)      )\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2727b288",
      "metadata": {
        "id": "2727b288"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]\n",
        "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]\n",
        "        )\n",
        "\n",
        "        self.ln_f    = nn.LayerNorm(  n_embd    )\n",
        "        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape     ## (Batch, 40)\n",
        "        ## ids and targets are both (B, T) tensors of integers\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))\n",
        "\n",
        "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
        "\n",
        "        ## This is the architecture\n",
        "        x = self.blocks(  x  )   ## (B, T, E)\n",
        "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
        "        logits = self.lm_ffw_head(x)         ## [B, 40, 65]\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, E  = logits.shape\n",
        "            logits  = logits.view( B*T, E)\n",
        "            targets = targets.view(B*T)\n",
        "            loss    = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
        "        for _ in range(max_new_tokens):\n",
        "            ## crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)    ## ## get preds\n",
        "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
        "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
        "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
        "        return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b674c77",
      "metadata": {
        "id": "1b674c77"
      },
      "outputs": [],
      "source": [
        "\n",
        "model   = GPTModel()\n",
        "\n",
        "m       = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(  m.parameters(), lr=learning_rate   )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13fac071",
      "metadata": {
        "id": "13fac071",
        "outputId": "f73b8f40-2a96-42c7-ebc8-2a4db27bdcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0: train loss 0.8657, val loss 1.1506\n",
            "step 500: train loss 0.8450, val loss 1.1416\n",
            "step 1000: train loss 0.8282, val loss 1.1522\n",
            "step 1500: train loss 0.8090, val loss 1.1400\n",
            "step 2000: train loss 0.7936, val loss 1.1367\n",
            "step 2500: train loss 0.7741, val loss 1.1417\n",
            "step 3000: train loss 0.7594, val loss 1.1363\n",
            "step 3500: train loss 0.7454, val loss 1.1351\n",
            "step 4000: train loss 0.7296, val loss 1.1525\n",
            "step 4500: train loss 0.7159, val loss 1.1473\n",
            "step 5000: train loss 0.7056, val loss 1.1382\n",
            "step 5500: train loss 0.6889, val loss 1.1480\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ## eval the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)   ## zero out\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be5cacb",
      "metadata": {
        "id": "8be5cacb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "## Starting token  id_sos = 0\n",
        "sos_context = torch.zeros(  (1, 1),  dtype=torch.long, device=device   )\n",
        "\n",
        "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
        "\n",
        "print(  decode(generated_text)   )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0992ae2a",
      "metadata": {
        "id": "0992ae2a",
        "outputId": "16a621bf-2018-4079-ffa0-2f52829c1615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " diminal ultrasound can older the body's ingoing condition.\n",
            "The board bodine valves infection\n",
            "Your pig procedure is scruced.\n",
            "Alabadeflie/causing BCE Mounan WisrapinKNews have in a compounded staff kidney case (surrored larglucanacross).\n",
            "If you, using a part of the arear that food safe that be strongerous disease that can be liquid stap air suboratory catheterin, several weeks).\n",
            "The pellets\n",
            "This means that think or sk from the usually developidosing in a neurothat exam), including or abit, can eas\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sos_context = torch.ones(  (1, 1),  dtype=torch.long, device=device   )\n",
        "\n",
        "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
        "\n",
        "print(  decode(generated_text)   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1452a762",
      "metadata": {
        "id": "1452a762"
      },
      "outputs": [],
      "source": [
        "\n",
        "new_lst = encode(\"cat disease\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b581fdf9",
      "metadata": {
        "id": "b581fdf9",
        "outputId": "18d50ce4-945c-4c8b-a41b-90d3fa6ac814"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([65, 63, 82,  1, 66, 71, 81, 67, 63, 81, 67])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "new_np = np.array(  new_lst   )\n",
        "new_np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58105edb",
      "metadata": {
        "id": "58105edb",
        "outputId": "88683a99-b642-4cc5-91a8-8f752e8db825"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[65, 63, 82,  1, 66, 71, 81, 67, 63, 81, 67]], device='cuda:0')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
        "\n",
        "\n",
        "new_context = new_context.view( (1, -1))\n",
        "new_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd205697",
      "metadata": {
        "id": "bd205697",
        "outputId": "5d82f388-0784-4a45-a2f6-d94e4e9041e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat diseases without what issues hardwarb, Americans air Repting Valotate breeds may preferable brain ispossed.\n",
            "This momeans In dogs without pets on the Americation Forms\n",
            "Learnading Brand Name: Tumors\n",
            "WARNIN®: What is E. consider this own, generally abnormal might neath and if many species of skin routine is negative, and alphalastra\n",
            "Urigital antibiotics hardly and solublish. Feed-sadded disease to come pets out what said culiculatins system.\n",
            "Asperatic unnown assess in this use condition is sometimes the a\n"
          ]
        }
      ],
      "source": [
        "\n",
        "generated_text = m.generate(new_context, max_new_tokens=500)[0].tolist()\n",
        "\n",
        "print(  decode(generated_text)   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a551f9bc",
      "metadata": {
        "id": "a551f9bc"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17f28116",
      "metadata": {
        "id": "17f28116"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05e7fefd",
      "metadata": {
        "id": "05e7fefd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cfe5408",
      "metadata": {
        "id": "6cfe5408"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe08e78",
      "metadata": {
        "id": "dbe08e78"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8d9c42",
      "metadata": {
        "id": "7f8d9c42"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac1a62f",
      "metadata": {
        "id": "8ac1a62f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c426f3f6",
      "metadata": {
        "id": "c426f3f6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7d4bfe",
      "metadata": {
        "id": "ca7d4bfe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b28825c",
      "metadata": {
        "id": "4b28825c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c737378f",
      "metadata": {
        "id": "c737378f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8 (Anaconda 2020.11)",
      "language": "python",
      "name": "anaconda-2020.11-py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}